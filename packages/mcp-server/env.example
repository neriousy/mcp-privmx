# PrivMX MCP Server Environment Configuration

# =============================================================================
# REQUIRED CONFIGURATION
# =============================================================================

# OpenAI API Configuration (REQUIRED for embeddings generation)
# Get your API key from: https://platform.openai.com/api-keys
OPENAI_API_KEY=your-openai-api-key

# =============================================================================
# QDRANT VECTOR DATABASE CONFIGURATION
# =============================================================================

# Qdrant Server URL (default: http://localhost:6333)
QDRANT_URL=http://localhost:6333

# Qdrant API Key (optional, only needed if authentication is enabled)
# QDRANT_API_KEY=your-qdrant-api-key

# =============================================================================
# VECTOR INDEX CACHING (Cold Start Optimization)
# =============================================================================

# Vector index cache file location (prevents re-indexing on cold starts)
# Default: .vector-index-cache.json (relative to project root)
# VECTOR_INDEX_CACHE_FILE=.vector-index-cache.json

# Collection name for vector embeddings
QDRANT_COLLECTION_NAME=privmx-docs

# Force re-indexing on startup (set to true only when needed)
# FORCE_VECTOR_REINDEX=false

# Select vector store backend (default: qdrant). Future options: pinecone, milvus
# VECTOR_BACKEND=qdrant

# =============================================================================
# OPTIONAL CONFIGURATION
# =============================================================================

# Embeddings Configuration
EMBEDDING_MODEL=text-embedding-3-small
EMBEDDING_BATCH_SIZE=50
EMBEDDING_MAX_TOKENS=8000

# Collection Configuration
QDRANT_VECTOR_SIZE=1536
QDRANT_DISTANCE_METRIC=Cosine

# Logging Configuration
LOG_LEVEL=info
LOG_FORMAT=pretty

# Data Paths (relative to packages/mcp-server)
DATA_PATH=../../../../data
CACHE_PATH=../../../../.cache

# Development Settings
NODE_ENV=development
DEBUG=false

# =============================================================================
# DOCKER ENVIRONMENT VARIABLES (for docker-compose setup)
# =============================================================================

# These are used by docker-compose.yml for Qdrant configuration
# QDRANT__SERVICE__API_KEY=your-secret-api-key
# QDRANT__SERVICE__MAX_REQUEST_SIZE_MB=32
# QDRANT__SERVICE__MAX_WORKERS=4

# =============================================================================
# PRODUCTION SETTINGS
# =============================================================================

# Performance Tuning
# VECTOR_SEARCH_TIMEOUT=30000
# VECTOR_SEARCH_CACHE_TTL=300
# MAX_CONCURRENT_SEARCHES=10

# Security
# ENABLE_API_KEY_AUTH=false
# API_KEY=your-mcp-server-api-key

# Monitoring
# ENABLE_METRICS=false
# METRICS_PORT=9090

# =============================================================================
# OBSERVABILITY / OPENTELEMETRY
# =============================================================================

# Enable distributed tracing (set to true to enable)
OTEL_ENABLED=false
# Select exporter: "otlp" (default) or "jaeger"
OTEL_EXPORTER=otlp
# Service name reported to tracing backend
OTEL_SERVICE_NAME=privmx-mcp-server
# OTLP HTTP endpoint (only for otlp exporter)
# OTLP_ENDPOINT=http://localhost:4318/v1/traces
# Jaeger collector endpoint (only for jaeger exporter)
# JAEGER_ENDPOINT=http://localhost:14268/api/traces

# Hybrid Search Weights (0-1 fractions that should sum to 1)
# Weight for lexical BM25 text search component
TEXT_WEIGHT=0.5
# Weight for vector semantic search component (fallback 1 - TEXT_WEIGHT)
VECTOR_WEIGHT=0.5

# API Hybrid Search Weights
API_TEXT_WEIGHT=0.5
API_VECTOR_WEIGHT=0.5

# =============================================================================
# USAGE EXAMPLES
# =============================================================================

# Basic setup (minimum required):
# OPENAI_API_KEY=sk-...your-key...

# Full local development setup:
# OPENAI_API_KEY=sk-...your-key...
# QDRANT_URL=http://localhost:6333
# LOG_LEVEL=debug
# DEBUG=true

# Production setup with authentication:
# OPENAI_API_KEY=sk-...your-key...
# QDRANT_URL=https://your-qdrant-instance.com
# QDRANT_API_KEY=your-qdrant-api-key
# NODE_ENV=production
# LOG_LEVEL=warn
# ENABLE_METRICS=true

# =============================================================================
# COLD START OPTIMIZATION NOTES
# =============================================================================

# The vector service now uses persistent caching to avoid re-indexing 
# documents on every cold start. The cache file tracks:
# - Document modification times
# - Content hashes for change detection
# - Qdrant collection status
# 
# This dramatically reduces initialization time on subsequent starts.
# 
# To force a complete re-index (useful after major documentation updates):
# 1. Delete the cache file: rm .vector-index-cache.json
# 2. Or set FORCE_VECTOR_REINDEX=true temporarily
# 3. Or use the force_reindex_documentation MCP tool 